{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTthYCfJOm-M",
        "outputId": "69f7f126-40a8-4963-fa08-fe0e5ffde7cf"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "print(tf. __version__) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgSY0aroO2OA"
      },
      "source": [
        "# import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HQpKg1_O7a-"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iev1_C91KXnu"
      },
      "source": [
        "x_val  = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val  = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wlP7zc6PIKM"
      },
      "source": [
        "x_train = x_train.reshape(50000, 784)\n",
        "x_val = x_val.reshape(10000, 784)\n",
        "x_test = x_test.reshape(10000, 784)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfKwNC6gPItc"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "gray_scale = 255\n",
        "x_train /= gray_scale\n",
        "x_val /= gray_scale\n",
        "x_test /= gray_scale"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCyxh4--PNkf"
      },
      "source": [
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frCLR0RrPPqZ"
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_awsODxPRoL"
      },
      "source": [
        "def mlp(x):\n",
        "    # hidden layer1\n",
        "    w1 = tf.Variable(tf.random_uniform([784,256]))\n",
        "    b1 = tf.Variable(tf.zeros([256]))\n",
        "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
        "    # hidden layer2\n",
        "    w2 = tf.Variable(tf.random_uniform([256,128]))\n",
        "    b2 = tf.Variable(tf.zeros([128]))\n",
        "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
        "    # output layer\n",
        "    w3 = tf.Variable(tf.random_uniform([128,10]))\n",
        "    b3 = tf.Variable(tf.zeros([10]))\n",
        "    logits= tf.matmul(h2, w3) + b3\n",
        "    \n",
        "    return logits"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMwukEvXPUCO"
      },
      "source": [
        "logits = mlp(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-MjPXeQPWVq"
      },
      "source": [
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "logits=logits, labels=y))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5CNYg4cPYYr"
      },
      "source": [
        "# initialize\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# train hyperparameters\n",
        "epoch_cnt = 30\n",
        "batch_size = 1000\n",
        "iteration = len(x_train) // batch_size"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MLMsWLParn",
        "outputId": "50f3845c-acd0-4111-b368-0374ef842484"
      },
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    for epoch in range(epoch_cnt):\n",
        "        avg_loss = 0.\n",
        "        start = 0; end = batch_size\n",
        "        \n",
        "        for i in range(iteration):\n",
        "            _, loss = sess.run([train_op, loss_op], \n",
        "                               feed_dict={x: x_train[start: end], y: y_train[start: end]})\n",
        "            start += batch_size; end += batch_size\n",
        "            # Compute average loss\n",
        "            avg_loss += loss / iteration\n",
        "            \n",
        "        # Validate model\n",
        "        preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "        # Calculate accuracy\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        cur_val_acc = accuracy.eval({x: x_val, y: y_val})\n",
        "        print(\"epoch: \"+str(epoch)+\", validation accuracy: \" \n",
        "              + str(cur_val_acc) +', loss: '+str(avg_loss))\n",
        "    \n",
        "    # Test model\n",
        "    preds = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    print(\"[Test Accuracy] :\", accuracy.eval({x: x_test, y: y_test}))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, validation accuracy: 0.0967, loss: 11570.591376953122\n",
            "epoch: 1, validation accuracy: 0.7818, loss: 326.71033813476566\n",
            "epoch: 2, validation accuracy: 0.8719, loss: 12.549036426544188\n",
            "epoch: 3, validation accuracy: 0.8895, loss: 7.307183084487915\n",
            "epoch: 4, validation accuracy: 0.8957, loss: 5.768688158988954\n",
            "epoch: 5, validation accuracy: 0.9018, loss: 4.743809337615968\n",
            "epoch: 6, validation accuracy: 0.9014, loss: 4.075223827362059\n",
            "epoch: 7, validation accuracy: 0.9036, loss: 3.659175968170165\n",
            "epoch: 8, validation accuracy: 0.8932, loss: 3.1618099355697638\n",
            "epoch: 9, validation accuracy: 0.894, loss: 3.30657993555069\n",
            "epoch: 10, validation accuracy: 0.9057, loss: 2.922093641757965\n",
            "epoch: 11, validation accuracy: 0.9005, loss: 2.6804901957511906\n",
            "epoch: 12, validation accuracy: 0.886, loss: 4.08508975982666\n",
            "epoch: 13, validation accuracy: 0.9064, loss: 2.8736781620979315\n",
            "epoch: 14, validation accuracy: 0.8898, loss: 2.567079949378967\n",
            "epoch: 15, validation accuracy: 0.8993, loss: 4.324074027538297\n",
            "epoch: 16, validation accuracy: 0.8954, loss: 3.5339373493194572\n",
            "epoch: 17, validation accuracy: 0.9008, loss: 3.9957014536857605\n",
            "epoch: 18, validation accuracy: 0.9173, loss: 2.9661187458038336\n",
            "epoch: 19, validation accuracy: 0.9188, loss: 3.2751586961746217\n",
            "epoch: 20, validation accuracy: 0.9124, loss: 2.345953183174133\n",
            "epoch: 21, validation accuracy: 0.9169, loss: 1.9917212319374082\n",
            "epoch: 22, validation accuracy: 0.9074, loss: 2.692356672286987\n",
            "epoch: 23, validation accuracy: 0.8896, loss: 2.6528946352004996\n",
            "epoch: 24, validation accuracy: 0.9152, loss: 3.019723494052887\n",
            "epoch: 25, validation accuracy: 0.9243, loss: 1.992853753566742\n",
            "epoch: 26, validation accuracy: 0.9171, loss: 1.765854772329331\n",
            "epoch: 27, validation accuracy: 0.9021, loss: 1.5799017834663387\n",
            "epoch: 28, validation accuracy: 0.9208, loss: 1.668588488101959\n",
            "epoch: 29, validation accuracy: 0.9147, loss: 1.4604841518402096\n",
            "[Test Accuracy] : 0.9123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtwDK0WFPf3j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}